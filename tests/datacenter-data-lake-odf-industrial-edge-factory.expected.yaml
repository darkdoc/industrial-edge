---
# Source: odf/templates/rbac/label-storage-bundle-sa.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: label-storage-nodes
  namespace: openshift-storage
  annotations:
    argocd.argoproj.io/sync-wave: "1"
---
# Source: odf/templates/rbac/label-storage-bundle-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  annotations:
    argocd.argoproj.io/sync-wave: "1"
  name: label-storage-nodes
rules:
  - apiGroups:
      - ""
    resources:
      - nodes
    verbs:
      - get
      - list
      - patch
      - update
---
# Source: odf/templates/rbac/label-storage-bundle-rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: label-storage-nodes
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: label-storage-nodes
subjects:
  - kind: ServiceAccount
    name: label-storage-nodes
    namespace: openshift-storage
---
# Source: odf/templates/label-storage-nodes-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  annotations:
    argocd.argoproj.io/sync-wave: "3"
  name: label-storage-nodes-bundle
spec:
  template:
    spec:
      containers:
        - image: image-registry.openshift-image-registry.svc:5000/openshift/cli:latest
          command:
            - /bin/bash
            - -c
            - |
              #!/usr/bin/env bash
              set -e
              if ! oc get nodes -l cluster.ocs.openshift.io/openshift-storage= ; then
                 echo "Worker nodes already labeled for storage"
                exit 0
              else
                # Wait for central to be ready
                attempt_counter=0
                max_attempts=20
                echo "Labeling all worker nodes for storage"
                oc label node -l node-role.kubernetes.io/worker= cluster.ocs.openshift.io/openshift-storage=
                echo "Worker nodes labeled for storage"
              fi
          imagePullPolicy: Always
          name: label-storage-nodes-bundle
      dnsPolicy: ClusterFirst
      restartPolicy: Never
      serviceAccount: label-storage-nodes
      serviceAccountName: label-storage-nodes
      terminationGracePeriodSeconds: 30
---
# Source: odf/templates/storagecluster.yaml
apiVersion: ocs.openshift.io/v1
kind: StorageCluster
metadata:
  annotations:
    uninstall.ocs.openshift.io/cleanup-policy: delete
    uninstall.ocs.openshift.io/mode: graceful
  name: ocs-storagecluster
  namespace: openshift-storage
  finalizers:
    - storagecluster.ocs.openshift.io
spec:
  arbiter: {}
  encryption:
    kms: {}
  externalStorage: {}
  managedResources:
    cephObjectStoreUsers: {}
    cephCluster: {}
    cephBlockPools: {}
    cephNonResilientPools: {}
    cephObjectStores: {}
    cephFilesystems: {}
    cephRBDMirror: {}
    cephToolbox: {}
    cephDashboard: {}
    cephConfig: {}
  mirroring: {}
  storageDeviceSets:
    - config: {}
      resources: {}
      placement: {}
      name: ocs-deviceset
      dataPVCTemplate:
        metadata: {}
        spec:
          accessModes:
            - ReadWriteOnce
          resources:
            requests:
              storage: 500Gi
          storageClassName: gp3-csi
          volumeMode: Block
        status: {}
      count: 1
      replica: 3
      portable: true
      preparePlacement: {}
---
# Source: odf/templates/storagesystem.yaml
apiVersion: odf.openshift.io/v1alpha1
kind: StorageSystem
metadata:
  finalizers:
    - storagesystem.odf.openshift.io
  name: ocs-storagecluster-storagesystem
  namespace: openshift-storage
spec:
  kind: storagecluster.ocs.openshift.io/v1
  name: ocs-storagecluster
  namespace: openshift-storage
